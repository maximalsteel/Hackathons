{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a023825c",
   "metadata": {},
   "source": [
    "# Predicting Data Scientists Salary in India"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cc87b8",
   "metadata": {},
   "source": [
    "Data scientist is the sexiest job in the world. How many times have you heard that? Analytics India Annual Salary Study which aims to understand a wide range of trends data science says that the median analytics salary in India for the year 2017 is INR 12.7 Lakhs across all experience level and skill sets. So given the job description and other key information can you predict the range of salary of the job posting? What kind of factors influence the salary of a data scientist? The study also says that in the world of analytics, Mumbai is the highest paymaster at almost 13.3 Lakhs per annum, followed by Bengaluru at 12.5 Lakhs. The industry of the data scientist can also influence the salary. Telecom industry pays the highest median salaries to its analytics professionals at 18.6 Lakhs. What are you waiting for, solve the problem by predicting how much a data scientist or analytics professional will be paid by analysing the data given. Bonus Tip: You can analyse the data and get key insights for your career as well. The best data scientists and machine learning engineers will be given awesome prizes at the end of hackathon. Share this hackathon with a colleague who may be interested in mining the dataset for insights and make great predictions. Data The dataset is based on salary and job postings in India across the internet. The train and the test data consists of attributes mentioned below. The rows of train dataset has rich amount of information regarding the job posting such as name of the designation and key skills required for the job. The training data and test data comprise of 19802 samples and of 6601 samples each. This is a dataset which has been collected over some time to gather relevant analytics jobs posting over the years. Features Name of the company (Encoded) Years of experience Job description Job designation Job Type Key skills Location Salary in Rupees Lakhs(To be predicted) Problem Statement Based on the given attributes and salary information, build a robust machine learning model that predicts the salary range of the salary post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f375eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier,RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import VotingClassifier,StackingClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix,cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score,roc_curve\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bddec7",
   "metadata": {},
   "source": [
    "## import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ce68a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('Final_Train_Dataset.csv')\n",
    "test = pd.read_csv('Final_Test_Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ab0016e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>experience</th>\n",
       "      <th>job_description</th>\n",
       "      <th>job_desig</th>\n",
       "      <th>job_type</th>\n",
       "      <th>key_skills</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "      <th>company_name_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5-7 yrs</td>\n",
       "      <td>Exp: Minimum 5 years;Good understanding of IOC...</td>\n",
       "      <td>Senior Exploit and Vulnerability Researcher</td>\n",
       "      <td>NaN</td>\n",
       "      <td>team skills, communication skills, analytical ...</td>\n",
       "      <td>Delhi NCR(Vikas Puri)</td>\n",
       "      <td>6to10</td>\n",
       "      <td>3687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10-17 yrs</td>\n",
       "      <td>He should have handled a team of atleast 5-6 d...</td>\n",
       "      <td>Head SCM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ppc, logistics, inventory management, supply c...</td>\n",
       "      <td>Sonepat</td>\n",
       "      <td>10to15</td>\n",
       "      <td>458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5-9 yrs</td>\n",
       "      <td>Must be an effective communicator (written &amp; s...</td>\n",
       "      <td>Deputy Manager - Talent Management &amp; Leadershi...</td>\n",
       "      <td>Analytics</td>\n",
       "      <td>HR Analytics, Employee Engagement, Training, S...</td>\n",
       "      <td>Delhi NCR</td>\n",
       "      <td>15to25</td>\n",
       "      <td>4195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7-10 yrs</td>\n",
       "      <td>7  -  10 years of overall experience in data e...</td>\n",
       "      <td>Associate Manager Data Engineering</td>\n",
       "      <td>Analytics</td>\n",
       "      <td>SQL, Javascript, Automation, Python, Ruby, Ana...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>10to15</td>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1-3 yrs</td>\n",
       "      <td>Chartered Accountancy degree or MBA in Finance...</td>\n",
       "      <td>TS- GSA- Senior Analyst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>accounting, finance, cash flow, financial plan...</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>3to6</td>\n",
       "      <td>1305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 experience                                    job_description  \\\n",
       "0           0    5-7 yrs  Exp: Minimum 5 years;Good understanding of IOC...   \n",
       "1           1  10-17 yrs  He should have handled a team of atleast 5-6 d...   \n",
       "2           2    5-9 yrs  Must be an effective communicator (written & s...   \n",
       "3           3   7-10 yrs  7  -  10 years of overall experience in data e...   \n",
       "4           4    1-3 yrs  Chartered Accountancy degree or MBA in Finance...   \n",
       "\n",
       "                                           job_desig   job_type  \\\n",
       "0        Senior Exploit and Vulnerability Researcher        NaN   \n",
       "1                                           Head SCM        NaN   \n",
       "2  Deputy Manager - Talent Management & Leadershi...  Analytics   \n",
       "3                 Associate Manager Data Engineering  Analytics   \n",
       "4                            TS- GSA- Senior Analyst        NaN   \n",
       "\n",
       "                                          key_skills               location  \\\n",
       "0  team skills, communication skills, analytical ...  Delhi NCR(Vikas Puri)   \n",
       "1  ppc, logistics, inventory management, supply c...                Sonepat   \n",
       "2  HR Analytics, Employee Engagement, Training, S...              Delhi NCR   \n",
       "3  SQL, Javascript, Automation, Python, Ruby, Ana...              Bengaluru   \n",
       "4  accounting, finance, cash flow, financial plan...                Gurgaon   \n",
       "\n",
       "   salary  company_name_encoded  \n",
       "0   6to10                  3687  \n",
       "1  10to15                   458  \n",
       "2  15to25                  4195  \n",
       "3  10to15                   313  \n",
       "4    3to6                  1305  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58fc26ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experience</th>\n",
       "      <th>job_description</th>\n",
       "      <th>job_desig</th>\n",
       "      <th>job_type</th>\n",
       "      <th>key_skills</th>\n",
       "      <th>location</th>\n",
       "      <th>company_name_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7-12 yrs</td>\n",
       "      <td>Professional experience in Java/J2EE based ser...</td>\n",
       "      <td>IT Technology Senior Consultant/java/ J2ee/ Se...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Java, J2Ee, Tomcat, JBoss, Weblogic, Oracle, E...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>2066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0-5 yrs</td>\n",
       "      <td>We are looking for 20+ Fresher/Experienced Can...</td>\n",
       "      <td>Medical Billing Process | International KPO | ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Medical Billing, Insurance Processing</td>\n",
       "      <td>Ahmedabad(Sola)</td>\n",
       "      <td>2629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3-6 yrs</td>\n",
       "      <td>Should understand overall integration framewor...</td>\n",
       "      <td>Oracle Sales Cloud Functional Consultant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Oracle Sales, Functional Consultancy, Troubles...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>2448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0-3 yrs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Looking For Freshers WHO WANT To Work WITH US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>offline, online, internet, part time, home bas...</td>\n",
       "      <td>Delhi NCR, Chennai, Hyderabad, Gurgaon, Luckno...</td>\n",
       "      <td>2711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0-5 yrs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Process Associate / Sr Process Associate / Tec...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>voice support, analytical skills, Process asso...</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  experience                                    job_description  \\\n",
       "0   7-12 yrs  Professional experience in Java/J2EE based ser...   \n",
       "1    0-5 yrs  We are looking for 20+ Fresher/Experienced Can...   \n",
       "2    3-6 yrs  Should understand overall integration framewor...   \n",
       "3    0-3 yrs                                                NaN   \n",
       "4    0-5 yrs                                                NaN   \n",
       "\n",
       "                                           job_desig job_type  \\\n",
       "0  IT Technology Senior Consultant/java/ J2ee/ Se...      NaN   \n",
       "1  Medical Billing Process | International KPO | ...      NaN   \n",
       "2           Oracle Sales Cloud Functional Consultant      NaN   \n",
       "3      Looking For Freshers WHO WANT To Work WITH US      NaN   \n",
       "4  Process Associate / Sr Process Associate / Tec...      NaN   \n",
       "\n",
       "                                          key_skills  \\\n",
       "0  Java, J2Ee, Tomcat, JBoss, Weblogic, Oracle, E...   \n",
       "1              Medical Billing, Insurance Processing   \n",
       "2  Oracle Sales, Functional Consultancy, Troubles...   \n",
       "3  offline, online, internet, part time, home bas...   \n",
       "4  voice support, analytical skills, Process asso...   \n",
       "\n",
       "                                            location  company_name_encoded  \n",
       "0                                          Bengaluru                  2066  \n",
       "1                                    Ahmedabad(Sola)                  2629  \n",
       "2                                          Bengaluru                  2448  \n",
       "3  Delhi NCR, Chennai, Hyderabad, Gurgaon, Luckno...                  2711  \n",
       "4                                          Hyderabad                    40  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69ae48a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19802, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b05dbaaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6601, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf7d9940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0              19802\n",
       "experience                129\n",
       "job_description          9059\n",
       "job_desig               11708\n",
       "job_type                    5\n",
       "key_skills              12951\n",
       "location                 1504\n",
       "salary                      6\n",
       "company_name_encoded     5035\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fe8f2ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "experience               110\n",
       "job_description         4064\n",
       "job_desig               5135\n",
       "job_type                   5\n",
       "key_skills              5589\n",
       "location                 803\n",
       "company_name_encoded    2752\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fdcf330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                  0\n",
       "experience                  0\n",
       "job_description          4418\n",
       "job_desig                   0\n",
       "job_type                15005\n",
       "key_skills                  1\n",
       "location                    0\n",
       "salary                      0\n",
       "company_name_encoded        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8e345b",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6866b6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna(subset=['key_skills'])\n",
    "\n",
    "df_train = train[['key_skills', 'job_desig', 'job_description', 'location', 'job_type', 'experience','salary']]\n",
    "df_test = test[['key_skills', 'job_desig', 'job_description', 'job_type', 'experience', 'location']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6dfd1424",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_skills(skl):\n",
    "    skills = str(skl).lower()\n",
    "    skills = re.sub('\\...','',skills)\n",
    "    skills = re.sub(',','',skills)\n",
    "    skills = re.sub(r'\\s+', ' ', skills)\n",
    "    return skills\n",
    "\n",
    "df_train['skills_cleaned'] = df_train['key_skills'].apply(clean_skills)\n",
    "df_test['skills_cleaned'] = df_test['key_skills'].apply(clean_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "160b32e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_skills</th>\n",
       "      <th>job_desig</th>\n",
       "      <th>job_description</th>\n",
       "      <th>location</th>\n",
       "      <th>job_type</th>\n",
       "      <th>experience</th>\n",
       "      <th>salary</th>\n",
       "      <th>skills_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>team skills, communication skills, analytical ...</td>\n",
       "      <td>Senior Exploit and Vulnerability Researcher</td>\n",
       "      <td>Exp: Minimum 5 years;Good understanding of IOC...</td>\n",
       "      <td>Delhi NCR(Vikas Puri)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5-7 yrs</td>\n",
       "      <td>6to10</td>\n",
       "      <td>team skills communication skills analytical sk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ppc, logistics, inventory management, supply c...</td>\n",
       "      <td>Head SCM</td>\n",
       "      <td>He should have handled a team of atleast 5-6 d...</td>\n",
       "      <td>Sonepat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10-17 yrs</td>\n",
       "      <td>10to15</td>\n",
       "      <td>ppc logistics inventory management supply chai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HR Analytics, Employee Engagement, Training, S...</td>\n",
       "      <td>Deputy Manager - Talent Management &amp; Leadershi...</td>\n",
       "      <td>Must be an effective communicator (written &amp; s...</td>\n",
       "      <td>Delhi NCR</td>\n",
       "      <td>Analytics</td>\n",
       "      <td>5-9 yrs</td>\n",
       "      <td>15to25</td>\n",
       "      <td>hr analytics employee engagement training succ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SQL, Javascript, Automation, Python, Ruby, Ana...</td>\n",
       "      <td>Associate Manager Data Engineering</td>\n",
       "      <td>7  -  10 years of overall experience in data e...</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Analytics</td>\n",
       "      <td>7-10 yrs</td>\n",
       "      <td>10to15</td>\n",
       "      <td>sql javascript automation python ruby analytic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>accounting, finance, cash flow, financial plan...</td>\n",
       "      <td>TS- GSA- Senior Analyst</td>\n",
       "      <td>Chartered Accountancy degree or MBA in Finance...</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1-3 yrs</td>\n",
       "      <td>3to6</td>\n",
       "      <td>accounting finance cash flow financial plannin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          key_skills  \\\n",
       "0  team skills, communication skills, analytical ...   \n",
       "1  ppc, logistics, inventory management, supply c...   \n",
       "2  HR Analytics, Employee Engagement, Training, S...   \n",
       "3  SQL, Javascript, Automation, Python, Ruby, Ana...   \n",
       "4  accounting, finance, cash flow, financial plan...   \n",
       "\n",
       "                                           job_desig  \\\n",
       "0        Senior Exploit and Vulnerability Researcher   \n",
       "1                                           Head SCM   \n",
       "2  Deputy Manager - Talent Management & Leadershi...   \n",
       "3                 Associate Manager Data Engineering   \n",
       "4                            TS- GSA- Senior Analyst   \n",
       "\n",
       "                                     job_description               location  \\\n",
       "0  Exp: Minimum 5 years;Good understanding of IOC...  Delhi NCR(Vikas Puri)   \n",
       "1  He should have handled a team of atleast 5-6 d...                Sonepat   \n",
       "2  Must be an effective communicator (written & s...              Delhi NCR   \n",
       "3  7  -  10 years of overall experience in data e...              Bengaluru   \n",
       "4  Chartered Accountancy degree or MBA in Finance...                Gurgaon   \n",
       "\n",
       "    job_type experience  salary  \\\n",
       "0        NaN    5-7 yrs   6to10   \n",
       "1        NaN  10-17 yrs  10to15   \n",
       "2  Analytics    5-9 yrs  15to25   \n",
       "3  Analytics   7-10 yrs  10to15   \n",
       "4        NaN    1-3 yrs    3to6   \n",
       "\n",
       "                                      skills_cleaned  \n",
       "0  team skills communication skills analytical sk...  \n",
       "1  ppc logistics inventory management supply chai...  \n",
       "2  hr analytics employee engagement training succ...  \n",
       "3  sql javascript automation python ruby analytic...  \n",
       "4  accounting finance cash flow financial plannin...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b49f5714",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.job_description.fillna('missing',inplace = True)\n",
    "test['job_description'].fillna('missing', inplace=True)\n",
    "\n",
    "def clean_job_desc(job):\n",
    "    job_desc = str(job).lower()\n",
    "    job_desc = re.sub(r'[^a-z]', ' ', job_desc)\n",
    "    job_desc = re.sub(r'\\s+', ' ', job_desc)\n",
    "    return job_desc\n",
    "\n",
    "df_train['job_desc_cleaned'] = df_train['job_description'].apply(clean_job_desc)\n",
    "df_test['job_desc_cleaned'] = df_test['job_description'].apply(clean_job_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fe28763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_location(loc):\n",
    "    location = loc.lower()\n",
    "    location = re.sub(r'[^a-z]', ' ', location)\n",
    "    location = re.sub(r'\\s+', ' ', location)\n",
    "    return location\n",
    "\n",
    "df_train['loc_cleaned'] = df_train['location'].apply(clean_location)\n",
    "df_test['loc_cleaned'] = df_test['location'].apply(clean_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "519ca190",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['job_type'].fillna('missingjobtype', inplace=True)\n",
    "train['job_type'].replace('Analytics', 'analytics', inplace=True)\n",
    "train['job_type'].replace('Analytic', 'analytics', inplace=True)\n",
    "train['job_type'].replace('ANALYTICS', 'analytics', inplace=True)\n",
    "train['job_type'].replace('analytic', 'analytics', inplace=True)\n",
    "\n",
    "test['job_type'].fillna('missingjobtype', inplace=True)\n",
    "test['job_type'].replace('Analytics', 'analytics', inplace=True)\n",
    "test['job_type'].replace('Analytic', 'analytics', inplace=True)\n",
    "test['job_type'].replace('ANALYTICS', 'analytics', inplace=True)\n",
    "test['job_type'].replace('analytic', 'analytics', inplace=True)\n",
    "\n",
    "df_train['job_type_cleaned'] = train['job_type'] \n",
    "df_test['job_type_cleaned'] = test['job_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f85a1176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "key_skills              0\n",
       "job_desig               0\n",
       "job_description      4417\n",
       "location                0\n",
       "job_type            15005\n",
       "experience              0\n",
       "salary                  0\n",
       "skills_cleaned          0\n",
       "job_desc_cleaned        0\n",
       "loc_cleaned             0\n",
       "job_type_cleaned        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26339019",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_exp(val):\n",
    "    exp = re.sub('-',' ',val)\n",
    "    exp = exp.split(\" \")\n",
    "    exp = int(exp[0])\n",
    "    return exp\n",
    "    \n",
    "def max_exp(val):\n",
    "    exp = re.sub('-',' ',val)\n",
    "    exp = exp.split(' ')\n",
    "    exp = int(exp[1])\n",
    "    return exp\n",
    "    \n",
    "df_train['min_exp'] = df_train['experience'].apply(lambda x : min_exp(x))\n",
    "df_train['max_exp'] = df_train['experience'].apply(lambda x : max_exp(x))\n",
    "\n",
    "df_test['min_exp'] = df_test['experience'].apply(lambda x : min_exp(x))\n",
    "df_test['max_exp'] = df_test['experience'].apply(lambda x : max_exp(x))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dcb51e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_job_desig(desig):\n",
    "    job_desig = desig.lower()\n",
    "    job_desig = re.sub(r'[^a-z]', ' ', job_desig)\n",
    "    job_desig = re.sub(r'\\s+', ' ', job_desig)\n",
    "    return job_desig\n",
    "\n",
    "df_train['desig_cleaned'] = df_train['job_desig'].apply(clean_job_desig)\n",
    "df_test['desig_cleaned'] = df_test['job_desig'].apply(clean_job_desig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a04fcbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['merged'] = (df_train['desig_cleaned'] + ' ' + df_train['job_desc_cleaned'] + ' ' + df_train['skills_cleaned']\n",
    "                      + ' ' + df_train['job_type_cleaned'])\n",
    "\n",
    "df_test['merged'] = (df_test['desig_cleaned'] + ' ' + df_test['job_desc_cleaned'] + ' ' + df_test['skills_cleaned']\n",
    "                     + ' ' + df_test['job_type_cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11b21400",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train  = df_train[['merged', 'loc_cleaned', 'min_exp', 'max_exp']] \n",
    "data_test = df_test[['merged', 'loc_cleaned', 'min_exp', 'max_exp']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62c8ec9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_train.rename(columns = {'merged':'emp_info'},inplace = False)\n",
    "data_test = data_test.rename(columns = {'merged':'emp_info'},inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7983e596",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_sal(sal):\n",
    "    val = str(sal).split(\"to\")\n",
    "    return val[0]\n",
    "def max_sal(sal):\n",
    "    val = str(sal).split(\"to\")\n",
    "    return val[1]\n",
    "\n",
    "target = pd.DataFrame()\n",
    "target[\"min_sal\"] = df_train[\"salary\"].apply(lambda x: min_sal(x))\n",
    "target[\"max_sal\"] = df_train[\"salary\"].apply(lambda x: max_sal(x))\n",
    "target1 = target.min_sal\n",
    "target2 = target.max_sal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f67b129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_sal</th>\n",
       "      <th>max_sal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  min_sal max_sal\n",
       "0       6      10\n",
       "1      10      15\n",
       "2      15      25\n",
       "3      10      15\n",
       "4       3       6"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f69ca3a",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6ff07e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "train['salary'] = le.fit_transform(train['salary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca593bf",
   "metadata": {},
   "source": [
    "# Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a12cb5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(\n",
    "    data_train,train['salary'], test_size=0.20, \n",
    "    stratify=train['salary'], random_state=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "74d5cf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of sample texts X_train:  15840\n",
      "No. of sample texts X_cv   :  3961\n"
     ]
    }
   ],
   "source": [
    "print('No. of sample texts X_train: ', len(X_train))\n",
    "print('No. of sample texts X_cv   : ', len(X_cv))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ef19ac",
   "metadata": {},
   "source": [
    "# Predictive Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0268ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_merged = X_train['emp_info']\n",
    "X_train_loc = X_train['loc_cleaned']\n",
    "\n",
    "X_cv_merged = X_cv['emp_info']\n",
    "X_cv_loc = X_cv['loc_cleaned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d89cf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "tf1 = TfidfVectorizer(min_df=3, token_pattern=r'\\w{3,}', ngram_range=(1,3), max_df=0.9)\n",
    "tf2 = TfidfVectorizer(min_df=2, token_pattern=r'\\w{3,}')\n",
    "\n",
    "X_train_merged = tf1.fit_transform(X_train_merged)\n",
    "X_train_loc = tf2.fit_transform(X_train_loc)\n",
    "\n",
    "X_cv_merged = tf1.transform(X_cv_merged)\n",
    "X_cv_loc = tf2.transform(X_cv_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "af470958",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc1 = StandardScaler()\n",
    "X_train_MinExp = sc1.fit_transform(np.array(X_train['min_exp']).reshape(-1,1))\n",
    "X_cv_MinExp = sc1.transform(np.array(X_cv['min_exp']).reshape(-1,1))\n",
    "X_train_MinExp = sparse.csr_matrix(X_train_MinExp)\n",
    "X_cv_MinExp = sparse.csr_matrix(X_cv_MinExp)\n",
    "\n",
    "sc2 = StandardScaler()\n",
    "X_train_MaxExp = sc2.fit_transform(np.array(X_train['max_exp']).reshape(-1,1))\n",
    "X_cv_MaxExp = sc2.transform(np.array(X_cv['max_exp']).reshape(-1,1))\n",
    "X_train_MaxExp = sparse.csr_matrix(X_train_MaxExp)\n",
    "X_cv_MaxExp = sparse.csr_matrix(X_cv_MaxExp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a218836e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack, csr_matrix\n",
    "\n",
    "merged_train = hstack((X_train_merged, X_train_loc, X_train_MinExp, X_train_MaxExp))\n",
    "merged_cv  = hstack((X_cv_merged, X_cv_loc, X_cv_MinExp, X_cv_MaxExp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6702a64f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15840, 52320), (3961, 52320))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_train.shape, merged_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c6cb218",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = []\n",
    "accu = []\n",
    "prec = []\n",
    "rec = []\n",
    "f1 = []\n",
    "kappa = []\n",
    "\n",
    "def model_validation(model, xtrain, ytrain, xtest, ytest):\n",
    "    m = model\n",
    "    m.fit(xtrain, ytrain)\n",
    "    pred_h = m.predict(xtest)\n",
    "    \n",
    "    # Print evaluation metrics\n",
    "    print('Confusion Matrix\\n', confusion_matrix(ytest, pred_h))\n",
    "    print('Classification Report\\n', classification_report(ytest, pred_h))\n",
    "    \n",
    "    # Print other metrics\n",
    "    print(f'Accuracy: {accuracy_score(ytest, pred_h):.4f}')\n",
    "    print(f'Recall: {recall_score(ytest, pred_h, average=\"weighted\"):.4f}')\n",
    "    print(f'Precision: {precision_score(ytest, pred_h, average=\"weighted\"):.4f}')\n",
    "    print(f'F1 Score: {f1_score(ytest, pred_h, average=\"weighted\"):.4f}')\n",
    "    print(f'Cohen Kappa: {cohen_kappa_score(ytest, pred_h):.4f}')\n",
    "    \n",
    "    # Save model evaluation metrics if needed\n",
    "    response = input('Do you want to save a model Y/N? ')\n",
    "    \n",
    "    if response.lower() == 'y':\n",
    "        global scorecard\n",
    "        mod.append(str(model))\n",
    "        accu.append(accuracy_score(ytest, pred_h))\n",
    "        rec.append(recall_score(ytest, pred_h, average='weighted'))\n",
    "        prec.append(precision_score(ytest, pred_h, average='weighted'))\n",
    "        f1.append(f1_score(ytest, pred_h, average='weighted'))\n",
    "        kappa.append(cohen_kappa_score(ytest, pred_h))\n",
    "\n",
    "        scorecard = pd.DataFrame({'Model': mod,\n",
    "                                 'Accuracy': accu,\n",
    "                                 'Precision': prec,\n",
    "                                 'Recall': rec,\n",
    "                                 'F1 Score': f1,\n",
    "                                 'Cohen Kappa': kappa})\n",
    "        print(scorecard)\n",
    "    else:\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d92167c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      " [[499  30   3   0  86  31]\n",
      " [ 25 368 263   5  32 207]\n",
      " [  7 313 356  71  10  68]\n",
      " [  5  26 148 132   0   4]\n",
      " [190  70  18   0 149 138]\n",
      " [ 58 249  89   8 122 181]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.77      0.70       649\n",
      "           1       0.35      0.41      0.38       900\n",
      "           2       0.41      0.43      0.42       825\n",
      "           3       0.61      0.42      0.50       315\n",
      "           4       0.37      0.26      0.31       565\n",
      "           5       0.29      0.26      0.27       707\n",
      "\n",
      "    accuracy                           0.43      3961\n",
      "   macro avg       0.44      0.42      0.43      3961\n",
      "weighted avg       0.42      0.43      0.42      3961\n",
      "\n",
      "Accuracy: 0.4254\n",
      "Recall: 0.4254\n",
      "Precision: 0.4212\n",
      "F1 Score: 0.4187\n",
      "Cohen Kappa: 0.2940\n",
      "Do you want to save a model Y/N? y\n",
      "                  Model  Accuracy  Precision    Recall  F1 Score  Cohen Kappa\n",
      "0  LogisticRegression()  0.425398   0.421242  0.425398  0.418732     0.293953\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model_validation(model, merged_train, y_train, merged_cv, y_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9495c6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      " [[535  52   7   0  23  32]\n",
      " [ 88 471 228  28   7  78]\n",
      " [ 47 247 406 102   4  19]\n",
      " [  6  44 118 142   0   5]\n",
      " [214 128  49   0  67 107]\n",
      " [119 257 116  14  40 161]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.82      0.65       649\n",
      "           1       0.39      0.52      0.45       900\n",
      "           2       0.44      0.49      0.46       825\n",
      "           3       0.50      0.45      0.47       315\n",
      "           4       0.48      0.12      0.19       565\n",
      "           5       0.40      0.23      0.29       707\n",
      "\n",
      "    accuracy                           0.45      3961\n",
      "   macro avg       0.46      0.44      0.42      3961\n",
      "weighted avg       0.45      0.45      0.42      3961\n",
      "\n",
      "Accuracy: 0.4499\n",
      "Recall: 0.4499\n",
      "Precision: 0.4464\n",
      "F1 Score: 0.4209\n",
      "Cohen Kappa: 0.3225\n",
      "Do you want to save a model Y/N? y\n",
      "                                 Model  Accuracy  Precision    Recall  \\\n",
      "0                 LogisticRegression()  0.425398   0.421242  0.425398   \n",
      "1  DecisionTreeClassifier(max_depth=5)  0.449886   0.446399  0.449886   \n",
      "\n",
      "   F1 Score  Cohen Kappa  \n",
      "0  0.418732     0.293953  \n",
      "1  0.420886     0.322489  \n"
     ]
    }
   ],
   "source": [
    "model_validation(DecisionTreeClassifier(max_depth=5),merged_train, y_train, merged_cv, y_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "23b44b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      " [[  0 649   0   0   0   0]\n",
      " [  0 894   6   0   0   0]\n",
      " [  0 818   7   0   0   0]\n",
      " [  0 314   1   0   0   0]\n",
      " [  0 565   0   0   0   0]\n",
      " [  0 703   4   0   0   0]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       649\n",
      "           1       0.23      0.99      0.37       900\n",
      "           2       0.39      0.01      0.02       825\n",
      "           3       0.00      0.00      0.00       315\n",
      "           4       0.00      0.00      0.00       565\n",
      "           5       0.00      0.00      0.00       707\n",
      "\n",
      "    accuracy                           0.23      3961\n",
      "   macro avg       0.10      0.17      0.06      3961\n",
      "weighted avg       0.13      0.23      0.09      3961\n",
      "\n",
      "Accuracy: 0.2275\n",
      "Recall: 0.2275\n",
      "Precision: 0.1325\n",
      "F1 Score: 0.0873\n",
      "Cohen Kappa: 0.0004\n",
      "Do you want to save a model Y/N? y\n",
      "                                               Model  Accuracy  Precision  \\\n",
      "0                               LogisticRegression()  0.425398   0.421242   \n",
      "1                DecisionTreeClassifier(max_depth=5)  0.449886   0.446399   \n",
      "2  RandomForestClassifier(max_depth=5, max_featur...  0.227468   0.132515   \n",
      "\n",
      "     Recall  F1 Score  Cohen Kappa  \n",
      "0  0.425398  0.418732     0.293953  \n",
      "1  0.449886  0.420886     0.322489  \n",
      "2  0.227468  0.087345     0.000438  \n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=150,max_features=11,max_depth=5)\n",
    "model_validation(model, merged_train, y_train, merged_cv, y_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0f71c7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      " [[478  39   3   0  69  60]\n",
      " [ 21 387 251   1  44 196]\n",
      " [  9 277 459   0  15  65]\n",
      " [  3  31 272   2   1   6]\n",
      " [166 102  11   1  97 188]\n",
      " [ 53 240  69   0  92 253]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.74      0.69       649\n",
      "           1       0.36      0.43      0.39       900\n",
      "           2       0.43      0.56      0.49       825\n",
      "           3       0.50      0.01      0.01       315\n",
      "           4       0.31      0.17      0.22       565\n",
      "           5       0.33      0.36      0.34       707\n",
      "\n",
      "    accuracy                           0.42      3961\n",
      "   macro avg       0.43      0.38      0.36      3961\n",
      "weighted avg       0.42      0.42      0.40      3961\n",
      "\n",
      "Accuracy: 0.4231\n",
      "Recall: 0.4231\n",
      "Precision: 0.4208\n",
      "F1 Score: 0.3973\n",
      "Cohen Kappa: 0.2842\n",
      "Do you want to save a model Y/N? y\n",
      "                                               Model  Accuracy  Precision  \\\n",
      "0                               LogisticRegression()  0.425398   0.421242   \n",
      "1                DecisionTreeClassifier(max_depth=5)  0.449886   0.446399   \n",
      "2  RandomForestClassifier(max_depth=5, max_featur...  0.227468   0.132515   \n",
      "3  AdaBoostClassifier(learning_rate=0.1, n_estima...  0.423125   0.420846   \n",
      "\n",
      "     Recall  F1 Score  Cohen Kappa  \n",
      "0  0.425398  0.418732     0.293953  \n",
      "1  0.449886  0.420886     0.322489  \n",
      "2  0.227468  0.087345     0.000438  \n",
      "3  0.423125  0.397321     0.284222  \n"
     ]
    }
   ],
   "source": [
    "model = AdaBoostClassifier(n_estimators=150,learning_rate=0.1)\n",
    "model_validation(model, merged_train, y_train, merged_cv, y_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ede77298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\users\\bhush\\anaconda3\\lib\\site-packages (4.5.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\bhush\\appdata\\roaming\\python\\python311\\site-packages (from lightgbm) (1.25.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\bhush\\anaconda3\\lib\\site-packages (from lightgbm) (1.11.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ecee8115",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2b84a86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.146417 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 110290\n",
      "[LightGBM] [Info] Number of data points in the train set: 15840, number of used features: 4432\n",
      "[LightGBM] [Info] Start training from score -1.808567\n",
      "[LightGBM] [Info] Start training from score -1.481605\n",
      "[LightGBM] [Info] Start training from score -1.568616\n",
      "[LightGBM] [Info] Start training from score -2.531427\n",
      "[LightGBM] [Info] Start training from score -1.947616\n",
      "[LightGBM] [Info] Start training from score -1.724030\n",
      "Confusion Matrix\n",
      " [[476  20   7   0 100  46]\n",
      " [ 23 334 308   7  41 187]\n",
      " [  8 267 369  99  16  66]\n",
      " [  3  31 135 142   1   3]\n",
      " [179  69  11   1 165 140]\n",
      " [ 54 232 115   8 126 172]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.73      0.68       649\n",
      "           1       0.35      0.37      0.36       900\n",
      "           2       0.39      0.45      0.42       825\n",
      "           3       0.55      0.45      0.50       315\n",
      "           4       0.37      0.29      0.33       565\n",
      "           5       0.28      0.24      0.26       707\n",
      "\n",
      "    accuracy                           0.42      3961\n",
      "   macro avg       0.43      0.42      0.42      3961\n",
      "weighted avg       0.41      0.42      0.41      3961\n",
      "\n",
      "Accuracy: 0.4186\n",
      "Recall: 0.4186\n",
      "Precision: 0.4123\n",
      "F1 Score: 0.4132\n",
      "Cohen Kappa: 0.2874\n",
      "Do you want to save a model Y/N? y\n",
      "                                               Model  Accuracy  Precision  \\\n",
      "0                               LogisticRegression()  0.425398   0.421242   \n",
      "1                DecisionTreeClassifier(max_depth=5)  0.449886   0.446399   \n",
      "2  RandomForestClassifier(max_depth=5, max_featur...  0.227468   0.132515   \n",
      "3  AdaBoostClassifier(learning_rate=0.1, n_estima...  0.423125   0.420846   \n",
      "4                                   LGBMClassifier()  0.418581   0.412288   \n",
      "\n",
      "     Recall  F1 Score  Cohen Kappa  \n",
      "0  0.425398  0.418732     0.293953  \n",
      "1  0.449886  0.420886     0.322489  \n",
      "2  0.227468  0.087345     0.000438  \n",
      "3  0.423125  0.397321     0.284222  \n",
      "4  0.418581  0.413196     0.287399  \n"
     ]
    }
   ],
   "source": [
    "lgb_model = lgb.LGBMClassifier()\n",
    "\n",
    "model_validation(lgb_model, merged_train, y_train, merged_cv, y_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672701da",
   "metadata": {},
   "source": [
    "Decision Tree Classifier has best results hence we will go with it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9462c9f1",
   "metadata": {},
   "source": [
    "# Prediction on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aebd6fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_merged = df_train['merged']\n",
    "X_train_loc = df_train['loc_cleaned']\n",
    "\n",
    "X_test_merged = df_test['merged']\n",
    "X_test_loc = df_test['loc_cleaned']\n",
    "\n",
    "y_train = df_train['salary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "20db50da",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf1 = TfidfVectorizer(min_df=3, token_pattern=r'\\w{3,}', ngram_range=(1,3))\n",
    "tf2 = TfidfVectorizer(min_df=2, token_pattern=r'\\w{3,}')\n",
    "\n",
    "X_train_merged = tf1.fit_transform(X_train_merged)\n",
    "X_train_loc = tf2.fit_transform(X_train_loc)\n",
    "\n",
    "X_test_merged = tf1.transform(X_test_merged)\n",
    "X_test_loc = tf2.transform(X_test_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b1bebb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc1 = StandardScaler()\n",
    "X_train_MinExp = sc1.fit_transform(np.array(df_train['min_exp']).reshape(-1,1))\n",
    "X_test_MinExp = sc1.transform(np.array(df_test['min_exp']).reshape(-1,1))\n",
    "X_train_MinExp = sparse.csr_matrix(X_train_MinExp)\n",
    "X_test_MinExp = sparse.csr_matrix(X_test_MinExp)\n",
    "\n",
    "sc2 = StandardScaler()\n",
    "X_train_MaxExp = sc2.fit_transform(np.array(df_train['max_exp']).reshape(-1,1))\n",
    "X_test_MaxExp = sc2.transform(np.array(df_test['max_exp']).reshape(-1,1))\n",
    "X_train_MaxExp = sparse.csr_matrix(X_train_MaxExp)\n",
    "X_test_MaxExp = sparse.csr_matrix(X_test_MaxExp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "afcee382",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_train = hstack((X_train_merged, X_train_loc, X_train_MinExp, X_train_MaxExp))\n",
    "merged_test = hstack((X_test_merged, X_test_loc, X_test_MinExp, X_test_MaxExp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "24d6aefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      " [[2375  230  101    2  462   75]\n",
      " [ 356 1771 1823  104  386   60]\n",
      " [ 145  787 2746  257  177   13]\n",
      " [  30  126  938  463   16    2]\n",
      " [ 863  573  292    5  884  207]\n",
      " [ 576 1206  802   32  601  315]]\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        0to3       0.55      0.73      0.63      3245\n",
      "      10to15       0.38      0.39      0.39      4500\n",
      "      15to25       0.41      0.67      0.51      4125\n",
      "      25to50       0.54      0.29      0.38      1575\n",
      "        3to6       0.35      0.31      0.33      2824\n",
      "       6to10       0.47      0.09      0.15      3532\n",
      "\n",
      "    accuracy                           0.43     19801\n",
      "   macro avg       0.45      0.41      0.40     19801\n",
      "weighted avg       0.44      0.43      0.40     19801\n",
      "\n",
      "Accuracy: 0.4320\n",
      "Recall: 0.4320\n",
      "Precision: 0.4369\n",
      "F1 Score: 0.3999\n",
      "Cohen Kappa: 0.3004\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(max_depth=5)\n",
    "\n",
    "# Train the model\n",
    "model.fit(merged_train, y_train)\n",
    "\n",
    "# Predict on the training data (for evaluation)\n",
    "train_predictions = model.predict(merged_train)\n",
    "\n",
    "# Evaluate the model on the training data\n",
    "print('Confusion Matrix\\n', confusion_matrix(y_train, train_predictions))\n",
    "print('Classification Report\\n', classification_report(y_train, train_predictions))\n",
    "\n",
    "print(f'Accuracy: {accuracy_score(y_train, train_predictions):.4f}')\n",
    "print(f'Recall: {recall_score(y_train, train_predictions, average=\"weighted\"):.4f}')\n",
    "print(f'Precision: {precision_score(y_train, train_predictions, average=\"weighted\"):.4f}')\n",
    "print(f'F1 Score: {f1_score(y_train, train_predictions, average=\"weighted\"):.4f}')\n",
    "print(f'Cohen Kappa: {cohen_kappa_score(y_train, train_predictions):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "803195ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on test data: ['15to25' '0to3' '10to15' ... '15to25' '15to25' '10to15']\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test data\n",
    "test_predictions = model.predict(merged_test)\n",
    "\n",
    "# Output the predictions\n",
    "print(\"Predictions on test data:\", test_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "101227c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = pd.DataFrame(data=test_predictions, columns=['salary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ad95bbaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xlsxwriter in c:\\users\\bhush\\anaconda3\\lib\\site-packages (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcf6d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the DataFrame to an Excel file\n",
    "with pd.ExcelWriter('output.xlsx', engine='xlsxwriter') as writer:\n",
    "    df_sub.to_excel(writer, sheet_name='Sheet1', index=False)\n",
    "\n",
    "print(\"Predictions saved to output.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
